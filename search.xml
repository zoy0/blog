<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>浅谈我为什么要设计一个IM系统</title>
      <link href="/p/8d64.html"/>
      <url>/p/8d64.html</url>
      
        <content type="html"><![CDATA[<h1 id="浅谈我为什么要设计一个IM系统"><a href="#浅谈我为什么要设计一个IM系统" class="headerlink" title="浅谈我为什么要设计一个IM系统"></a>浅谈我为什么要设计一个IM系统</h1><h2 id="想法的萌发"><a href="#想法的萌发" class="headerlink" title="想法的萌发"></a>想法的萌发</h2><p>我曾经负责的一个学校项目因为使用人数增多，系统负载太高，当学生开始上实验课时，系统有一定几率会出现各种问题，如CPU过高，响应速度变慢等，于是，为了日后支撑更高的访问量，我尝试着将该微服务横向扩展，即部署集群服务。</p><p>在此期间，因为之前一直是单机部署，所以代码有不少都没有考虑到微服务会出现的情况。这是我在部署集群时遇到的一个难点之一，特别是测验模块中的websocket，如果集群部署的话，那么多个实例中的不同session就无法进行通信。于是，我开始寻找解决方案。寻找途中，我被 <a href="http://www.52im.net/">即时通讯网 - 即时通讯开发者社区! (52im.net)</a> 中的内容所吸引，从里面了解到了长连接通信中可能会出现的各种问题。此时，想尝试写一个IM系统的种子已然在心中萌发。</p><h2 id="为什么要开始做IM项目"><a href="#为什么要开始做IM项目" class="headerlink" title="为什么要开始做IM项目"></a>为什么要开始做IM项目</h2><p>在看完 52im 网各方大佬的帖子后，我就觉得IM并不是一个容易的项目，恰恰相反，它的功能虽然简单，但是实现起来要考虑的却非常多。在国内IM产品中，哪怕QQ，微信等一直被人所贬低，但是毫无疑问，作为一个即时通讯软件，它们都是很优秀的。虽然从大一开始学习JAVA，也开发和维护了一些项目，但是却一直未从零开始设计并实现一个完整可用的系统。对于现在的我来说，IM项目是具有一定的挑战性的，因此我希望能借此项目提高我的技术，并在github上开源，熟悉github的操作流程。</p><h2 id="IM即时通讯的难点及挑战"><a href="#IM即时通讯的难点及挑战" class="headerlink" title="IM即时通讯的难点及挑战"></a>IM即时通讯的难点及挑战</h2><h3 id="前端问题"><a href="#前端问题" class="headerlink" title="前端问题"></a>前端问题</h3><p>作为一名后端开发人员，我对前端并没有深入了解。若是只论普通写个demo小页面，还勉强能有个形状，但是像这种要求比较高的，就属实无能为力了。不过还好有一个资深前端大佬帮忙😋，才能让这个IM项目能有个好看的界面。但即使这样，作为IM客户端，功能实现起来也不是一件容易事。另一方面，因为我们对PC，IOS，Android端都不甚了解，因此目前只有web端。</p><h3 id="IM性能问题"><a href="#IM性能问题" class="headerlink" title="IM性能问题"></a>IM性能问题</h3><p>一套成熟的IM系统，毫无疑问是要顶住高并发量的，同时要保证消息的实时性，可靠性，一致性，幂等性。比如在一个群聊中，用户发的消息要保证能发送到每一位群成员手上，不丢消息，延迟低而且消息不能乱序，同时在弱网环境下，也不能出现消息重传导致接收者接收到多条同样的消息。这些实现起来都是有一定难度的。</p><h3 id="功能问题"><a href="#功能问题" class="headerlink" title="功能问题"></a>功能问题</h3><p>如果设计出来的IM系统仅仅只有文本聊天功能，那毫无疑问是一个很无趣的系统。因此，在聊天频道中，图片，语音，文件，表情包等，都可以成为一种需求。而要如何存储，如何展示，这也是难点之一。</p><h2 id="记录下自己完成该IM项目的过程"><a href="#记录下自己完成该IM项目的过程" class="headerlink" title="记录下自己完成该IM项目的过程"></a>记录下自己完成该IM项目的过程</h2><p>在飞书知识库中写下IM项目的项目文档，这也算是项目的一个发展路程。</p><p>同时，接下来也会在博客上继续记录开发开发过程。</p><h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p>团队：<a href="https://github.com/AnyTopVv">AnyTopVv (github.com)</a> 团队名是基于某几个有意义的词组成的🤗</p><p>项目命名：ATVV-IM</p><p>前端地址：<a href="https://github.com/AnyTopVv/atvv-im-frontend">AnyTopVv&#x2F;atvv-im-frontend: atvv-im前端仓库 (github.com)</a></p><p>后端地址：<a href="https://github.com/AnyTopVv/atvv-im">AnyTopVv&#x2F;atvv-im (github.com)</a></p>]]></content>
      
      
      <categories>
          
          <category> IM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 浅谈系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis日常学习(持续更新)</title>
      <link href="/p/1893.html"/>
      <url>/p/1893.html</url>
      
        <content type="html"><![CDATA[<h1 id="Reids持久化机制"><a href="#Reids持久化机制" class="headerlink" title="Reids持久化机制"></a>Reids持久化机制</h1><h2 id="自测"><a href="#自测" class="headerlink" title="自测"></a>自测</h2><p><strong>怎么保证 Redis 挂掉之后再重启数据可以进行恢复？</strong> ⭐⭐⭐⭐⭐</p><p><strong>什么是 RDB 持久化？</strong> ⭐⭐⭐⭐⭐</p><p><strong>什么是 AOF 持久化？</strong> ⭐⭐⭐⭐⭐</p><p><strong>Redis 4.0 对于持久化机制做了什么优化？</strong> ⭐⭐⭐⭐</p><h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p>使用缓存的时候，我们经常需要对内存中的数据进行持久化也就是将内存中的数据写入到硬盘中。大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了做数据同步（比如 Redis 集群的主从节点通过 RDB 文件同步数据）。</p><p>Redis支持三种持久化方式: RDB, AOF, RDB和AOF混合持久化</p><h3 id="RDB方式持久化"><a href="#RDB方式持久化" class="headerlink" title="RDB方式持久化"></a>RDB方式持久化</h3><p>默认采用的持久化方式</p><p>Redis 可以通过创建快照来获得存储在内存里面的数据在 <strong>某个时间点</strong> 上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。</p><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，save会堵塞主进程，而bgsave则是fork出一个子进程执行快照备份。<br>redis.conf相关配置</p><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol"><span class="token keyword">save</span> <span class="token number">900</span> <span class="token number">1</span>           #在<span class="token number">900</span>秒<span class="token punctuation">(</span><span class="token number">15</span>分钟<span class="token punctuation">)</span>之后，如果至少有<span class="token number">1</span>个<span class="token keyword">key</span>发生变化，Redis就会自动触发bgsave命令创建快照。<span class="token keyword">save</span> <span class="token number">300</span> <span class="token number">10</span>          #在<span class="token number">300</span>秒<span class="token punctuation">(</span><span class="token number">5</span>分钟<span class="token punctuation">)</span>之后，如果至少有<span class="token number">10</span>个<span class="token keyword">key</span>发生变化，Redis就会自动触发bgsave命令创建快照。<span class="token keyword">save</span> <span class="token number">60</span> <span class="token number">10000</span>        #在<span class="token number">60</span>秒<span class="token punctuation">(</span><span class="token number">1</span>分钟<span class="token punctuation">)</span>之后，如果至少有<span class="token number">10000</span>个<span class="token keyword">key</span>发生变化，Redis就会自动触发bgsave命令创建快照。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>bgsava 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的。关键的技术就在于<strong>写时复制技术</strong>(<em><strong>Copy-On-Write, COW</strong></em>)。</p><p>执行 bgsava 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。</p><p><img src="https://img.lazysun.me/202310092117416.webp" alt="img"></p><p>只有在发生修改内存数据的情况时，物理内存才会被复制一份。</p><p><img src="https://img.lazysun.me/202310092116866.webp" alt="img"></p><p>当主线程和子线程都只是读共享数据时，内存没有任何变化，但是如果主线程发生了写操作，如主线程要<strong>修改共享数据里的某一块数据</strong>（比如键值对 A）时，就会发生写时复制，于是这块数据的<strong>物理内存就会被复制一份（键值对</strong> <strong>A’）</strong>，然后<strong>主线程在这个数据副本（键值对A’）进行修改操作</strong>。与此同时，<strong>bgsave 子进程可以继续把原来的数据（键值对</strong> <strong>A）写入到 RDB 文件</strong>。</p><p>写时复制可以保证bgsave生成的RDB文件是某个时间点的全量快照，但是再某种极端情况下，如<strong>键值对被大量修改</strong>，会复制出大量副本，占用许多内存空间。因此，在写操作比较频繁时，需要监控redis的内存变化</p><h3 id="AOF方式持久化"><a href="#AOF方式持久化" class="headerlink" title="AOF方式持久化"></a>AOF方式持久化</h3><p>AOF 持久化的实时性更好。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化（Redis 6.0 之后已经默认是开启了），可以通过 <code>appendonly</code> 参数开启：</p><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol">appendonly yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>开启AOF后，每执行一条修改数据的命令后都会将该命令写入到AOF缓冲区<code>server.aof_buf</code>中，然后再写入AOF文件中，最后根据fsync策略决定何时进行刷盘。</p><h4 id="AOF的基本流程"><a href="#AOF的基本流程" class="headerlink" title="AOF的基本流程"></a>AOF的基本流程</h4><ol><li>命令追加(appen)：每一条修改数据的命令都会被添加到AOF缓冲区</li><li>文件写入(write)：由AOF缓冲区写入AOF文件，使用<code>write</code>函数，此时数据被写入系统内核缓冲区，需要等待系统调度或者 <code>fsync</code> 方法强制刷新缓冲区，同步到磁盘</li><li>文件同步(fsync)：AOF 缓冲区根据对应的持久化方式（ <code>fsync</code> 策略）向硬盘做同步操作。这一步需要调用 <code>fsync</code> 函数（系统调用）， <code>fsync</code> 针对单个文件操作，对其进行强制硬盘同步，<code>fsync</code> 将阻塞直到写入磁盘完成后返回，保证了数据持久化。</li><li>文件重写(rewrite)：AOF文件过大时，会进行压缩。</li><li>重写加载(load)：重启redis时，读取AOF文件的数据进行恢复</li></ol><h4 id="AOF持久化方式-fsync策略"><a href="#AOF持久化方式-fsync策略" class="headerlink" title="AOF持久化方式(fsync策略)"></a>AOF持久化方式(fsync策略)</h4><ol><li><strong>appendfsync always</strong>：每一次调用write方法后调用fsync同步到磁盘，会严重降低redis的性能。</li><li><strong>appendfsync everysec</strong>：执行命令，调用 write 方法后立即返回，每隔1s调用fsync进行刷盘。</li><li><strong>appendfsync no</strong>：执行命令，调用 write 方法后立即返回，让系统自行同步到磁盘。</li></ol><h4 id="AOF重写"><a href="#AOF重写" class="headerlink" title="AOF重写"></a>AOF重写</h4><p>当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。</p><p><img src="https://img.lazysun.me/202310092114801.png" alt="image-20231009205745562"></p><h4 id="AOF校检机制"><a href="#AOF校检机制" class="headerlink" title="AOF校检机制"></a>AOF校检机制</h4><p>AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。这个机制的原理其实非常简单，就是通过使用一种叫做 <strong>校验和（checksum）</strong> 的数字来验证 AOF 文件。这个校验和是通过对整个 AOF 文件内容进行 CRC64 算法计算得出的数字。如果文件内容发生了变化，那么校验和也会随之改变。因此，Redis 在启动时会比较计算出的校验和与文件末尾保存的校验和（计算的时候会把最后一行保存校验和的内容给忽略点），从而判断 AOF 文件是否完整。如果发现文件有问题，Redis 就会拒绝启动并提供相应的错误信息。AOF 校验机制十分简单有效，可以提高 Redis 数据的可靠性。</p><h4 id="RDB-AOF混合方式"><a href="#RDB-AOF混合方式" class="headerlink" title="RDB-AOF混合方式"></a>RDB-AOF混合方式</h4><p>fork出来的子进程将内存副本全量已RDB的方式写入到AOP临时文件，再将重写缓冲区的增量以AOF的方式添加到临时文件末尾，最后将RDB + AOF混合的AOF文件取代旧的AOF文件。</p><h1 id="Redis线程模式"><a href="#Redis线程模式" class="headerlink" title="Redis线程模式"></a>Redis线程模式</h1><h2 id="自测-1"><a href="#自测-1" class="headerlink" title="自测"></a>自测</h2><p><strong>Redis 单线程模型了解吗？ 既然是单线程，那怎么监听大量的客户端连接呢？、为什么 Redis 这么快？</strong>⭐⭐⭐⭐⭐</p><p><strong>Redis6.0 之前为什么不使用多线程？</strong> ⭐⭐⭐</p><p><strong>Redis6.0 之后为何引入了多线程？</strong> ⭐⭐⭐⭐</p><h2 id="单线程模式"><a href="#单线程模式" class="headerlink" title="单线程模式"></a>单线程模式</h2><p>Redis采用<strong>Reactor模式</strong>的网络模型</p><p>主线程负责数据(键值对)的读写和网络IO传输，而多线程负责大key的删除和后台快照备份等。Redis在处理客户端的请求时包括获取（socket读）、解析、执行、内容返回（socket写）等都由一个<strong>顺序串行的主线程处理</strong>，</p><h3 id="为什么选择单线程"><a href="#为什么选择单线程" class="headerlink" title="为什么选择单线程"></a>为什么选择单线程</h3><ul><li>开发和维护更简单</li><li>也可以并发处理客户端的请求(IO多路复用和非堵塞IO)</li><li>主要瓶颈是内存和网络带宽，而非CPU</li></ul><h3 id="为什么这么快"><a href="#为什么这么快" class="headerlink" title="为什么这么快"></a>为什么这么快</h3><ul><li>基于内存操作</li><li>数据结构简单，数据操作基本上都是O(1)复杂度</li><li>IO多路复用和epoll函数</li><li>避免上下文切换</li></ul><h2 id="浅谈IO多路复用和NIO"><a href="#浅谈IO多路复用和NIO" class="headerlink" title="浅谈IO多路复用和NIO"></a>浅谈IO多路复用和NIO</h2><p>因为IO多路复用和NIO有点类似，这里就放在一起谈了</p><h4 id="NIO（NonBlocking-IO）"><a href="#NIO（NonBlocking-IO）" class="headerlink" title="NIO（NonBlocking IO）"></a>NIO（NonBlocking IO）</h4><p><code>NIO</code>这里要进行区分：</p><ol><li>JAVA中代表 <code>New IO</code>。</li><li>系统操作层面代表<code>NonBlocking</code></li></ol><p>这里所说的并非java的NIO(New IO)</p><p>同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。<strong>应用程序不断进行 I&#x2F;O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的</strong>，会造成CPU空转。</p><h4 id="IO多路复用"><a href="#IO多路复用" class="headerlink" title="IO多路复用"></a>IO多路复用</h4><blockquote><ol><li><code>select</code>函数 - &gt; 同步多路复用<code>IO</code>方法<br> 返回值中会返回三个集合数据包含 <code>readfds</code>,<code>writefds</code>以及<code>exceptfds</code>文件描述符集合。(<code>fds</code>有<code>1024</code>限制)</li><li><code>poll</code>函数  - &gt; 同步多路复用<code>IO</code>方法<br> 返回值中返回对应有响应的<code>fds</code>集合。</li><li><code>epoll_create</code>函数  - &gt; 打开<code>epoll</code>文件描述符<br> 该方法将会返回一个<code>epoll</code>实例（该实例用于接收<code>IO</code>事件通知）。</li><li><code>epoll_ctl</code>函数  - &gt; <code>epoll</code>描述符的控制接口<br> 接收<code>fd</code>绑定对应事件到<code>epoll</code>实例上。</li><li><code>epoll_wait</code>函数  - &gt; 等待<code>epoll</code>文件描述符上<code>IO</code>事件<br> 返回对应有<code>IO</code>事件的<code>fd</code>。</li></ol><p>  上述方法中，前两个都是基于多路复用进行的，下面三个方法则完全归属于<code>epoll</code>方式（个人觉得他也使用到了多路复用，但是更偏向于<code>Reactor</code>模型）。</p></blockquote><p>IO多路复用，是建立在内核上提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题；用户将需要进行IO操作的socket添加到select中，然后阻塞等待select系统调用返回。当数据到达时，socket被激活，select函数返回，用户线程发起read请求，读取数据并继续执行。使用select函数进行IO请求与同步阻塞模型并无太大区别，甚至多添加监视socket，select函数额外操作，使用优势主要在于用户可以在一个线程内同时处理多个socket的IO请求，用户可以注册多个socket，然后不断调用select读取被激活的socket，即可达到在同一个线程内同时处理多个IO请求的目的。</p><p>和NIO的区别是select获取到的都是有数据的。</p><h2 id="redis事件机制"><a href="#redis事件机制" class="headerlink" title="redis事件机制"></a>redis事件机制</h2><p>Redis中的事件驱动库只关注网络IO，以及定时器。该事件库处理下面两类事件：</p><ul><li>文件事件(file event)：用于处理 Redis 服务器和客户端之间的网络IO。</li><li>时间事件(time eveat)：Redis 服务器中的一些操作（比如serverCron函数）需要在给定的时间点执行，而时间事件就是处理这类定时操作的。</li></ul><p><img src="https://img.lazysun.me/202310101950780.png" alt="事件管理器示意图"></p><p><code>aeEventLoop</code>是整个事件驱动的核心，它管理着文件事件表和时间事件列表，不断地循环处理着就绪的文件事件和到期的时间事件。</p><p>尽管多个文件事件可能会并发地出现，但I&#x2F;O多路复用程序总是会将所有产生的套接字都放到同一个队列(也就是后文中描述的<code>aeEventLoop</code>的<code>fired</code>就绪事件表)里边，然后文件事件处理器会以有序、同步、单个套接字的方式处理该队列中的套接字，也就是处理就绪的文件事件。</p><p>一次 Redis 客户端与服务器进行连接并且发送命令的过程如上图所示。</p><ul><li>客户端向服务端发起建立 socket 连接的请求，那么监听套接字将产生 AE_READABLE 事件，触发<strong>连接应答处理器</strong>执行。处理器会对客户端的连接请求进行应答，然后创建客户端套接字，以及客户端状态，并将客户端套接字的 AE_READABLE 事件与<strong>命令请求处理器</strong>关联。</li><li>客户端建立连接后，向服务器发送命令，那么客户端套接字将产生 AE_READABLE 事件，触发<strong>命令请求处理器</strong>执行，处理器读取客户端命令，然后传递给相关程序去执行。</li><li>执行命令获得相应的命令回复，为了将命令回复传递给客户端，服务器将客户端套接字的 AE_WRITEABLE 事件与<strong>命令回复处理器</strong>关联。当客户端试图读取命令回复时，客户端套接字产生 AE_WRITEABLE 事件，触发命令<strong>回复处理器</strong>将命令回复全部写入到套接字中。</li></ul><p>事件处理：</p><p><code>aeMain</code>函数以一个无限循环不断地调用<code>aeProcessEvents</code>函数来处理所有的事件。</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">aeMain</span><span class="token punctuation">(</span>aeEventLoop <span class="token operator">*</span>eventLoop<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    eventLoop<span class="token operator">-></span>stop <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>eventLoop<span class="token operator">-></span>stop<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token comment">/* 如果有需要在事件处理前执行的函数，那么执行它 */</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>eventLoop<span class="token operator">-></span>beforesleep <span class="token operator">!=</span> <span class="token constant">NULL</span><span class="token punctuation">)</span>            eventLoop<span class="token operator">-></span><span class="token function">beforesleep</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">/* 开始处理事件*/</span>        <span class="token function">aeProcessEvents</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">,</span> AE_ALL_EVENTS<span class="token operator">|</span>AE_CALL_AFTER_SLEEP<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>参考文章</p><ol><li><a href="https://blog.csdn.net/qq_44377709/article/details/123724519">请不要再说NIO和多路复用IO是同一个东西了（内含BIO、NIO、多路复用、Netty、AIO案例测试代码）_io多路复用和nio的关系_默辨的博客-CSDN博客</a></li><li><a href="https://cloud.tencent.com/developer/article/1745899">图解BIO、NIO、AIO、多路复用IO的区别-腾讯云开发者社区-腾讯云 (tencent.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/646111642">【Redis】高级篇： 一篇文章讲清楚Redis的单线程和多线程 - 知乎 (zhihu.com)</a></li><li><a href="https://javaguide.cn/database/redis/redis-questions-01.html#redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E4%BA%86%E8%A7%A3%E5%90%97">Redis常见面试题总结(上) | JavaGuide(Java面试 + 学习指南)</a></li><li><a href="http://remcarpediem.net/article/1aa2da89/">Redis 事件机制详解 | 程序员历小冰 (remcarpediem.net)</a></li></ol></blockquote><h1 id="Redis内存管理"><a href="#Redis内存管理" class="headerlink" title="Redis内存管理"></a>Redis内存管理</h1><h2 id="redis设置缓存过期时间"><a href="#redis设置缓存过期时间" class="headerlink" title="redis设置缓存过期时间"></a>redis设置缓存过期时间</h2><p>内存资源是有限的，所以缓存数据需要过期时间，不然会导致oom</p><p>Redis自带了给缓存数据设置过期时间的功能，但是除了字符串类型有独有的设置过期时间 <code>setex</code> 外，其他类型都需要依靠 <code>expire</code> 命令来设置过期时间。这意味着一些api (如redisTemplate) 添加键值对的同时设置过期时间需要2条命令。</p><h2 id="redis内存淘汰机制"><a href="#redis内存淘汰机制" class="headerlink" title="redis内存淘汰机制"></a>redis内存淘汰机制</h2><p>6种数据淘汰策略</p><blockquote><ol><li><p><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据集（<code>server.db[i].expires</code>）中挑选最近最少使用的数据淘汰。</p></li><li><p><strong>volatile-ttl</strong>：从已设置过期时间的数据集（<code>server.db[i].expires</code>）中挑选将要过期的数据淘汰。</p></li><li><p><strong>volatile-random</strong>：从已设置过期时间的数据集（<code>server.db[i].expires</code>）中任意选择数据淘汰。</p></li><li><p><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。</p></li><li><p><strong>allkeys-random</strong>：从数据集（<code>server.db[i].dict</code>）中任意选择数据淘汰。</p></li><li><p><strong>no-eviction</strong>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</p><p>4.0 版本后增加：</p></li><li><p><strong>volatile-lfu（least frequently used）</strong>：从已设置过期时间的数据集（<code>server.db[i].expires</code>）中挑选最不经常使用的数据淘汰。</p></li><li><p><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。</p></li></ol><hr><p>著作权归JavaGuide(javaguide.cn)所有 基于MIT协议 原文链接：<a href="https://javaguide.cn/database/redis/redis-questions-01.html">https://javaguide.cn/database/redis/redis-questions-01.html</a></p></blockquote><h1 id="Redis数据结构类型"><a href="#Redis数据结构类型" class="headerlink" title="Redis数据结构类型"></a>Redis数据结构类型</h1><h2 id="5种基本类型"><a href="#5种基本类型" class="headerlink" title="5种基本类型"></a>5种基本类型</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>String 是一种二进制安全的数据类型，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p><strong>需要存储常规数据的场景</strong></p><ul><li>举例：缓存 Session、Token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</li><li>相关命令：<code>SET</code>、<code>GET</code>。</li></ul><p><strong>需要计数的场景</strong></p><ul><li>举例：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li><li>相关命令：<code>SET</code>、<code>GET</code>、 <code>INCR</code>、<code>DECR</code> 。</li></ul><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>Redis 的 List 的实现为一个 <strong>双向链表</strong>，可以支持反向查找和遍历。</p><h4 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h4><p><strong>信息流展示</strong></p><ul><li>举例：最新文章、最新动态。</li><li>相关命令：<code>LPUSH</code>、<code>LRANGE</code>。</li></ul><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>Redis 中的 Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一。可以基于 Set 轻易实现交集、并集、差集的操作。</p><p><strong>需要存放的数据不能重复的场景</strong></p><ul><li>举例：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li><li>相关命令：<code>SCARD</code>（获取集合数量） 。</li></ul><p><strong>需要获取多个数据源交集、并集和差集的场景</strong></p><ul><li>举例：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。</li><li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li></ul><p><strong>需要随机获取数据源中的元素的场景</strong></p><ul><li>举例：抽奖系统、随机点名等场景。</li><li>相关命令：<code>SPOP</code>（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、<code>SRANDMEMBER</code>（随机获取集合中的元素，适合允许重复中奖的场景）。</li></ul><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p>Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表</p><p>对于同样是存储字符串，Hash与String的主要区别：</p><p>1、把所有相关的值聚集到一个key中，节省内存空间；</p><p>2、只使用一个key，减少key冲突；</p><p>3、当需要批量获取值的时候，只需要使用一个命令，减少内存&#x2F;IO&#x2F;CPU的消耗</p><p>当然Hash也不是随意可以使用的，在以下场景便不适合使用：</p><p>1、<strong>field不能单独设置过期时间，只能对key设置过期时间</strong>，所以，过期时当前key下所有field的数据全部过期；</p><p>2、没有bit操作(位运算)；</p><p>3、需要考虑数据量分布的问题（value值非常大的时候，无法分布到多个节点）；</p><h4 id="具体数据结构"><a href="#具体数据结构" class="headerlink" title="具体数据结构"></a>具体数据结构</h4><p>类似jdk1.7的HashMap<br>外层的redis K-V用到了HashTable，而内层的Hash数据类型(即redis key的value值为hash类型)，可以使用ziplist和hashtable实现。</p><h5 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a>ziplist</h5><p>ziplist存储时用的是一段连续分配的内存空间，和hashtable相比使用的内存更少，和linkList相比效率更高</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">同时满足以下条件时使用ziplist：1. 哈希对象保存的所有键值的字符串长度小于64字节；2. 哈希对象保存的键值对数量小于512个；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://img.lazysun.me/202310161614026.png" alt="img"></p><p>添加新kv的时候会添加到压缩队列表尾</p><h5 id="hashtable"><a href="#hashtable" class="headerlink" title="hashtable"></a>hashtable</h5><p><img src="https://img.lazysun.me/202310161616851.png" alt="img"></p><h6 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h6><p>size: 哈希表大小</p><p>sizemask：size-1，用于对hash过的值进行取模</p><p>used：value个数</p><h6 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h6><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">dict</span> <span class="token punctuation">&#123;</span>    dictType <span class="token operator">*</span>type<span class="token punctuation">;</span>                        <span class="token comment">// 和类型相关的处理函数</span>    <span class="token keyword">void</span> <span class="token operator">*</span>privdata<span class="token punctuation">;</span>                        <span class="token comment">// 上述类型函数对应的可选参数</span>    dictht ht<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                          <span class="token comment">// 两张哈希表，ht[0]为原生哈希表，ht[1]为 rehash 哈希表</span>    <span class="token keyword">long</span> rehashidx<span class="token punctuation">;</span>                        <span class="token comment">// 当等于-1时表示没有在 rehash，否则表示 rehash 的下标</span>    <span class="token keyword">int</span> iterators<span class="token punctuation">;</span>                         <span class="token comment">// 迭代器数量(暂且不谈)</span><span class="token punctuation">&#125;</span> dict<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>hash函数与jdk1.7的hashmap类似</p><p>插入键值对时会判断是否正在rehash，根据是否在 rehash 选择对应的哈希表，分配哈希表节点 dictEntry 的内存空间，执行插入，插入操作始终在链表头插入。</p><p><strong>渐进式rehash</strong></p><p>扩展或者收缩哈希表的时候，需要将 ht[0] 里面所有的键值对 rehash 到 ht[1] 里，当键值对数量非常多的时候，这个操作如果在一帧内完成，大量的计算很可能导致服务器宕机，所以不能一次性完成，需要渐进式的完成。</p><p>渐进式 rehash 的详细步骤如下：</p><ol><li>为 ht[1] 分配指定空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表；</li><li>将 rehashidx 设置为0，表示正式开始 rehash。</li><li>在进行 rehash 期间，每次对字典执行 增、删、改、查操作时，程序除了执行指定的操作外，还会将 哈希表 ht[0].table中下标为 rehashidx 位置上的所有的键值对 全部迁移到 ht[1].table 上，完成后 rehashidx 自增。</li><li>最后，当 ht[0].used 变为0时，代表所有的键值对都已经从 ht[0] 迁移到 ht[1] 了，释放 ht[0].table， 并且将 ht[0] 设置为 ht[1]，rehashidx 标记为 -1 代表 rehash 结束。</li></ol><h4 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h4><p><strong>可用于对象存储</strong></p><h3 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h3><p>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 <code>score</code>，使得集合中的元素能够按 <code>score</code> 进行有序排列，还可以通过 <code>score</code> 的范围来获取元素的列表。</p><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>字典+跳跃表</p><h4 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h4><p><strong>需要随机获取数据源中的元素根据某个权重进行排序的场景</strong></p><ul><li>举例：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li>相关命令：<code>ZRANGE</code> (从小到大排序)、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><p><strong>需要存储的数据有优先级或者重要程度的场景</strong> 比如优先级任务队列。</p><ul><li>举例：优先级任务队列。</li><li>相关命令：<code>ZRANGE</code> (从小到大排序)、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><p>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 <code>score</code>，使得集合中的元素能够按 <code>score</code> 进行有序排列，还可以通过 <code>score</code> 的范围来获取元素的列表。</p><h1 id="Redis-生产问题"><a href="#Redis-生产问题" class="headerlink" title="Redis 生产问题"></a>Redis 生产问题</h1><p>待更新…..</p>]]></content>
      
      
      <categories>
          
          <category> 日常学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> nosql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMq知识集锦</title>
      <link href="/p/5180.html"/>
      <url>/p/5180.html</url>
      
        <content type="html"><![CDATA[<h1 id="RabbitMq知识集锦"><a href="#RabbitMq知识集锦" class="headerlink" title="RabbitMq知识集锦"></a>RabbitMq知识集锦</h1><h2 id="rabbitmq基本概念"><a href="#rabbitmq基本概念" class="headerlink" title="rabbitmq基本概念"></a>rabbitmq基本概念</h2><p>略</p><h2 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h2><h3 id="1-为什么推荐用MQ取代线程池？"><a href="#1-为什么推荐用MQ取代线程池？" class="headerlink" title="1. 为什么推荐用MQ取代线程池？"></a>1. 为什么推荐用MQ取代线程池？</h3><p>多线程的好处是增加服务器并行处理的效率，一般用于大量数据处理比较耗时，将其分为多个块，并行处理；或者外部接口调用比较耗时，不想堵塞同步接口。并且线程有个丢弃策略，消息丢失是否可以接受也是有待商议的。所以有一个方法就是通过mq将手里的活交给其他服务去处理。</p><p>MQ的好处:</p><ol><li>为了降低rt，有时候我们会使用mq进行自发自收</li><li>临时数据存储，能处理多少数据不再依赖于jvm的内存大小，而取决于mq的配置</li><li>处理能力的可控性，通过查看mq管控平台得知消费和生产速率，决定是否要扩缩容</li><li>可靠性，提供可持久化，宕机或者重启可恢复数据，而线程池的数据存在于内存，重启就没了</li><li>可扩展性好，不会因为单机瓶颈影响性能</li><li>跨语言平台，可用其他高性能语言作为消费者处理消息，加快消费速率</li></ol><p>看 <a href="https://www.bilibili.com/video/BV1Aw411i7jx/">为什么我推荐用MQ取代线程池？_哔哩哔哩_bilibili </a>  总结</p>]]></content>
      
      
      <categories>
          
          <category> note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>grafana告警</title>
      <link href="/p/ddc4.html"/>
      <url>/p/ddc4.html</url>
      
        <content type="html"><![CDATA[<h1 id="Grafana告警"><a href="#Grafana告警" class="headerlink" title="Grafana告警"></a>Grafana告警</h1><p>继 <a href="https://lazysun.me/p/f651.html">服务器监控系统 | lazysun</a> ，这次需要设置告警，提前预警可能出现的错误。</p><h2 id="docker安装node-exporter，node-exporter，cadvisor"><a href="#docker安装node-exporter，node-exporter，cadvisor" class="headerlink" title="docker安装node-exporter，node-exporter，cadvisor"></a>docker安装node-exporter，node-exporter，cadvisor</h2><p>docker-compose.yaml</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">networks</span><span class="token punctuation">:</span>  <span class="token key atrule">monitoring</span><span class="token punctuation">:</span>    <span class="token key atrule">driver</span><span class="token punctuation">:</span> bridge<span class="token key atrule">services</span><span class="token punctuation">:</span>  <span class="token key atrule">node-exporter</span><span class="token punctuation">:</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> prom/node<span class="token punctuation">-</span>exporter<span class="token punctuation">:</span>latest    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter    <span class="token key atrule">restart</span><span class="token punctuation">:</span> unless<span class="token punctuation">-</span>stopped    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> /proc<span class="token punctuation">:</span>/host/proc<span class="token punctuation">:</span>ro      <span class="token punctuation">-</span> /sys<span class="token punctuation">:</span>/host/sys<span class="token punctuation">:</span>ro      <span class="token punctuation">-</span> /<span class="token punctuation">:</span>/rootfs<span class="token punctuation">:</span>ro    <span class="token key atrule">command</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token string">'--path.procfs=/host/proc'</span>      <span class="token punctuation">-</span> <span class="token string">'--path.rootfs=/rootfs'</span>      <span class="token punctuation">-</span> <span class="token string">'--path.sysfs=/host/sys'</span>      <span class="token punctuation">-</span> <span class="token string">'--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'</span>    <span class="token key atrule">expose</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token number">9100</span>    <span class="token key atrule">networks</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> monitoring  <span class="token key atrule">node-exporter</span><span class="token punctuation">:</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> prom/prometheus<span class="token punctuation">:</span>latest    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> prometheus    <span class="token key atrule">restart</span><span class="token punctuation">:</span> unless<span class="token punctuation">-</span>stopped    <span class="token key atrule">ports</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token string">'8003:9090'</span>    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> ./prometheus.yml<span class="token punctuation">:</span>/etc/prometheus/prometheus.yml      <span class="token punctuation">-</span> ./prometheus_data<span class="token punctuation">:</span>/prometheus    <span class="token key atrule">command</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token string">'--config.file=/etc/prometheus/prometheus.yml'</span>      <span class="token punctuation">-</span> <span class="token string">'--storage.tsdb.path=/prometheus'</span>      <span class="token punctuation">-</span> <span class="token string">'--web.console.libraries=/etc/prometheus/console_libraries'</span>      <span class="token punctuation">-</span> <span class="token string">'--web.console.templates=/etc/prometheus/consoles'</span>      <span class="token punctuation">-</span> <span class="token string">'--web.enable-lifecycle'</span>    <span class="token key atrule">expose</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token number">9090</span>    <span class="token key atrule">networks</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> monitoring  <span class="token key atrule">cadvisor</span><span class="token punctuation">:</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> google/cadvisor<span class="token punctuation">:</span>latest    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> cadvisor    <span class="token key atrule">restart</span><span class="token punctuation">:</span> unless<span class="token punctuation">-</span>stopped    <span class="token key atrule">expose</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token number">8080</span>    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> /<span class="token punctuation">:</span>/rootfs<span class="token punctuation">:</span>ro      <span class="token punctuation">-</span> /var/run<span class="token punctuation">:</span>/var/run<span class="token punctuation">:</span>rw      <span class="token punctuation">-</span> /sys<span class="token punctuation">:</span>/sys<span class="token punctuation">:</span>ro      <span class="token punctuation">-</span> /var/lib/docker/<span class="token punctuation">:</span>/var/lib/docker<span class="token punctuation">:</span>ro    <span class="token key atrule">networks</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> monitoring<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>prometheus.yaml</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># my global config</span><span class="token key atrule">global</span><span class="token punctuation">:</span>  <span class="token key atrule">scrape_interval</span><span class="token punctuation">:</span> 15s <span class="token comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span>  <span class="token key atrule">evaluation_interval</span><span class="token punctuation">:</span> 15s <span class="token comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span>  <span class="token comment"># scrape_timeout is set to the global default (10s).</span><span class="token comment"># Alertmanager configuration</span><span class="token key atrule">alerting</span><span class="token punctuation">:</span>  <span class="token key atrule">alertmanagers</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span>          <span class="token comment"># - alertmanager:9093</span><span class="token comment"># Load rules once and periodically evaluate them according to the global 'evaluation_interval'.</span><span class="token key atrule">rule_files</span><span class="token punctuation">:</span>  <span class="token comment"># - "first_rules.yml"</span>  <span class="token comment"># - "second_rules.yml"</span><span class="token comment"># A scrape configuration containing exactly one endpoint to scrape:</span><span class="token comment"># Here it's Prometheus itself.</span><span class="token key atrule">scrape_configs</span><span class="token punctuation">:</span>  <span class="token comment"># The job name is added as a label `job=&lt;job_name>` to any timeseries scraped from this config.</span>  <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">"prometheus"</span>    <span class="token comment"># metrics_path defaults to '/metrics'</span>    <span class="token comment"># scheme defaults to 'http'.</span>    <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"localhost:9090"</span><span class="token punctuation">,</span><span class="token string">"node-exporter:9100"</span><span class="token punctuation">,</span><span class="token string">"cadvisor:8080"</span><span class="token punctuation">]</span>    <span class="token comment"># 这个是将instance设置为主机名，否则instance会变成"localhost:9090","node-exporter:9100","cadvisor:8080"，很不直观</span>    <span class="token key atrule">relabel_configs</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">source_labels</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>__address__<span class="token punctuation">]</span>      <span class="token key atrule">regex</span><span class="token punctuation">:</span> <span class="token string">'.*'</span>      <span class="token key atrule">target_label</span><span class="token punctuation">:</span> instance      <span class="token key atrule">replacement</span><span class="token punctuation">:</span> <span class="token string">'主机名'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之后设置grafana收集prometheus指标即可</p><h2 id="grafana仪表盘"><a href="#grafana仪表盘" class="headerlink" title="grafana仪表盘"></a>grafana仪表盘</h2><p>node-exporter推荐: 12385 , 1860</p><p>cadvisor推荐：193</p><p>loki: 自定义</p><h2 id="grafana设置告警信息"><a href="#grafana设置告警信息" class="headerlink" title="grafana设置告警信息"></a>grafana设置告警信息</h2><p>因为我在grafana9.3版本没有找到设置message的字段，所以选择在annotations中加入重要信息解析，然后用webhook发送到转发中间件，再发送到飞书(后面一些原因我将grafana升级到10版本以上后发现有message了)</p><h3 id="日志告警"><a href="#日志告警" class="headerlink" title="日志告警"></a>日志告警</h3><p>使用正则表达式提取日志重要信息</p><p>springboot应用日志格式如下:</p><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token number">2023</span><span class="token operator">-</span><span class="token number">07</span><span class="token operator">-</span><span class="token number">30</span> <span class="token number">12</span><span class="token operator">:</span><span class="token number">31</span><span class="token operator">:</span><span class="token number">23.826</span> <span class="token constant">ERROR</span> <span class="token number">6</span> <span class="token operator">--</span><span class="token operator">-</span> <span class="token punctuation">[</span><span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">5672</span><span class="token punctuation">]</span> <span class="token class-name"><span class="token namespace">o<span class="token punctuation">.</span>s<span class="token punctuation">.</span>a<span class="token punctuation">.</span>r<span class="token punctuation">.</span>c<span class="token punctuation">.</span></span>CachingConnectionFactory</span>       <span class="token operator">:</span> <span class="token class-name">Channel</span> shutdown<span class="token operator">:</span> channel error<span class="token punctuation">;</span> protocol method<span class="token operator">:</span> #method<span class="token generics"><span class="token punctuation">&lt;</span>channel<span class="token punctuation">.</span>close<span class="token punctuation">></span></span><span class="token punctuation">(</span>reply<span class="token operator">-</span>code<span class="token operator">=</span><span class="token number">406</span><span class="token punctuation">,</span> reply<span class="token operator">-</span>text<span class="token operator">=</span><span class="token constant">PRECONDITION_FAILED</span> <span class="token operator">-</span> delivery acknowledgement on channel <span class="token number">344</span> timed <span class="token class-name"><span class="token namespace">out<span class="token punctuation">.</span></span> Timeout</span> value used<span class="token operator">:</span> <span class="token number">1800000</span> <span class="token class-name"><span class="token namespace">ms<span class="token punctuation">.</span></span> This</span> timeout value can be configured<span class="token punctuation">,</span> see consumers doc guide <span class="token keyword">to</span> <span class="token namespace">learn</span> more<span class="token punctuation">,</span> <span class="token keyword">class</span><span class="token operator">-</span>id<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> method<span class="token operator">-</span>id<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>正则表达式可如下:</p><pre class="line-numbers language-regexp" data-language="regexp"><code class="language-regexp">(?P&lt;alert_time&gt;\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;\\s\\d&#123;1,2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125;)\\s*(?P&lt;level&gt;INFO|ERROR|DEBUG|WARN|CRITICAL)\\s*\\d+\\s*---\\s*\\[(?P&lt;Thread&gt;(.*?))\\]\\s*(?P&lt;logger&gt;(.*?)):\\s*(?P&lt;message&gt;[\\s\\S]*)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>获得labels: alert_time，level，Thread，logger，message</p><p>随后可在grafana alerting中create alert rule，</p><p><img src="https://img.lazysun.me/202307301351570.png" alt="202307301351570"></p><p>这里解释一下几个比较重要的参数</p><p>告警条件:</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">sum <span class="token keyword">by</span> <span class="token punctuation">(</span>app<span class="token punctuation">,</span> <span class="token keyword">level</span><span class="token punctuation">,</span> alert_time<span class="token punctuation">,</span> thread<span class="token punctuation">,</span> logger<span class="token punctuation">,</span> message<span class="token punctuation">)</span>   <span class="token punctuation">(</span>count_over_time<span class="token punctuation">(</span>   &#123;app<span class="token operator">=</span><span class="token string">"user-service"</span><span class="token punctuation">,</span> <span class="token keyword">level</span><span class="token operator">=</span><span class="token string">"ERROR"</span>&#125;    <span class="token operator">!=</span> <span class="token identifier"><span class="token punctuation">`</span>discard long time none received connection<span class="token punctuation">`</span></span>   <span class="token operator">|</span> <span class="token operator">regexp</span> <span class="token string">"(?P&lt;alert_time>\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;\\s\\d&#123;1,2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;.\\d&#123;3&#125;)\\s*(?P&lt;level>INFO|ERROR|DEBUG|WARN|CRITICAL)\\s*\\d+\\s*---\\s*\\[(?P&lt;Thread>(.*?))\\]\\s*(?P&lt;logger>(.*?)):\\s*(?P&lt;message>[\\s\\S]*)"</span><span class="token punctuation">[</span><span class="token number">1</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每分钟评测一次，当评测sql数据大于0时就会发出告警，告警内容中我在annotaions自定义了header和json属性，header作为飞书卡片的标题，json作为传输数据会被中间件处理，然后分别发出。</p><p>json数据:</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#123;</span> range $k<span class="token punctuation">,</span> $v <span class="token operator">:</span>= $values <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#123;</span><span class="token property">"app"</span><span class="token operator">:</span> <span class="token string">"&#123;&#123; index $v.Labels "</span>app<span class="token string">" &#125;&#125;"</span><span class="token punctuation">,</span><span class="token property">"alertTime"</span><span class="token operator">:</span> <span class="token string">"&#123;&#123; index $v.Labels "</span>alert_time<span class="token string">" &#125;&#125;"</span><span class="token punctuation">,</span><span class="token property">"level"</span><span class="token operator">:</span> <span class="token string">"&lt;font color='red'>&#123;&#123; index $v.Labels "</span>level<span class="token string">" &#125;&#125;&lt;/font>"</span><span class="token punctuation">,</span><span class="token property">"logger"</span><span class="token operator">:</span> <span class="token string">"&#123;&#123; index $v.Labels "</span>logger<span class="token string">" &#125;&#125;"</span><span class="token punctuation">,</span><span class="token property">"message"</span><span class="token operator">:</span> <span class="token string">"&#123;&#123; index $v.Labels "</span>message<span class="token string">" &#125;&#125;"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#123;</span> end <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>后面在Notifications设置label，规定发送路由alertRouting，Alert触发后会根据这个参数进行自定义通知。</p><p>设置联络点和路由:</p><p><img src="https://img.lazysun.me/202307301402394.png" alt="image-20230730140257700"></p><h3 id="主机资源告警"><a href="#主机资源告警" class="headerlink" title="主机资源告警"></a>主机资源告警</h3><p>设置与日志类似，可以与仪表盘相结合</p><h4 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h4><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token number">1</span><span class="token operator">-</span><span class="token function">avg</span><span class="token punctuation">(</span>irate<span class="token punctuation">(</span>node_cpu_seconds_total&#123;instance<span class="token operator">=</span><span class="token operator">~</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span><span class="token keyword">mode</span><span class="token operator">=</span><span class="token string">"idle"</span>&#125;<span class="token punctuation">[</span><span class="token number">1</span>m<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>发送内容(同样由中间件转发):</p><pre class="line-numbers language-none"><code class="language-none">主机: 设置的主机名cpu使用率大于80,cpu使用率为&#123;&#123; $values.B0 &#125;&#125;%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h4><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">(</span><span class="token function">sum</span><span class="token punctuation">(</span>node_memory_MemTotal_bytes&#123;instance<span class="token operator">=</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span> job<span class="token operator">=</span><span class="token string">"prometheus"</span>&#125; <span class="token operator">-</span> node_memory_MemAvailable_bytes&#123;instance<span class="token operator">=</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span> job<span class="token operator">=</span><span class="token string">"prometheus"</span>&#125;<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token function">sum</span><span class="token punctuation">(</span>node_memory_MemTotal_bytes&#123;instance<span class="token operator">=</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span> job<span class="token operator">=</span><span class="token string">"prometheus"</span>&#125;<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span><span class="token number">100</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="磁盘空间"><a href="#磁盘空间" class="headerlink" title="磁盘空间"></a>磁盘空间</h4><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token number">100</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>node_filesystem_avail_bytes&#123;instance<span class="token operator">=</span><span class="token operator">~</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span>job<span class="token operator">=</span><span class="token operator">~</span><span class="token string">"prometheus"</span><span class="token punctuation">,</span>device<span class="token operator">!</span><span class="token operator">~</span><span class="token string">'rootfs'</span>&#125; <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">/</span> node_filesystem_size_bytes&#123;instance<span class="token operator">=</span><span class="token operator">~</span><span class="token string">"设置的主机名"</span><span class="token punctuation">,</span>job<span class="token operator">=</span><span class="token operator">~</span><span class="token string">"prometheus"</span><span class="token punctuation">,</span>device<span class="token operator">!</span><span class="token operator">~</span><span class="token string">'rootfs'</span>&#125;<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>网上关于grafana的资料描述的都有些模糊，所以我根据自己的理解自定义了这个告警，使用体验还行，但是因为创建模板使用的模板语言我看不懂，且需要的告警规则不多，我便手动添加了(扩展起来不变),同时使用中间件进行转发<a href="https://github.com/zoy0/nacos-notify">GitHub - zoy0&#x2F;nacos-notify</a>，看起来会舒服很多，但是应该是不规范的。</p>]]></content>
      
      
      <categories>
          
          <category> tasks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
            <tag> prometheus </tag>
            
            <tag> 日志 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一次磁盘不足的问题</title>
      <link href="/p/f7b9.html"/>
      <url>/p/f7b9.html</url>
      
        <content type="html"><![CDATA[<h1 id="docker日志占用过大问题"><a href="#docker日志占用过大问题" class="headerlink" title="docker日志占用过大问题"></a>docker日志占用过大问题</h1><p>df -h 查看存储空间使用情况，发现 &#x2F;data 目录空间已满</p><p><img src="https://img.lazysun.me/202302272358805.png"></p><p>docker清理不出多余的空间了</p><p><img src="https://img.lazysun.me/202302272358942.png" alt="img"></p><p>查看docker目录下占用情况</p><p><img src="https://img.lazysun.me/202302272359556.png" alt="img"></p><p>分别查看overlay2和containers目录下占用情况</p><p><img src="https://img.lazysun.me/202302272359385.png" alt="img"></p><p>overlay2:</p><p><img src="https://img.lazysun.me/202302272359755.png" alt="img"></p><pre class="line-numbers language-Bash" data-language="Bash"><code class="language-Bash">docker ps -q | xargs docker inspect --format &#39;&#123;&#123;.State.Pid&#125;&#125;, &#123;&#123;.Id&#125;&#125;, &#123;&#123;.Name&#125;&#125;, &#123;&#123;.GraphDriver.Data.WorkDir&#125;&#125;&#39; | grep &quot;357860f908577317c242ff3ff7005744dd7bd22e4504a2716780ec3db07f462a&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>发现nacos和mysql占用比较大的存储空间(nacos不是很理解为什么这么大)</p><p>Containers:</p><pre class="line-numbers language-Bash" data-language="Bash"><code class="language-Bash">[root@localhost containers]# docker ps -a | grep e706624efe706624efba9   lafyun&#x2F;instance-controller:latest                       &quot;docker-entrypoint.s…&quot;   4 months ago    Up 4 months   0.0.0.0:49155-&gt;9000&#x2F;tcp, :::49155-&gt;9000&#x2F;tcp                                                                                                           docker-compose-instance-controller-1[root@localhost containers]# docker ps -a | grep c0f11440fadc0f11440fad1   grafana&#x2F;loki:2.2.0                                      &quot;&#x2F;usr&#x2F;bin&#x2F;loki -conf…&quot;   3 months ago    Up 3 months   0.0.0.0:3100-&gt;3100&#x2F;tcp, :::3100-&gt;3100&#x2F;tcp                                                                                                             test-loki<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>发现loki占用很大，暂时停掉删除</p><p>解决方法：</p><p><img src="https://img.lazysun.me/202302272359567.png" alt="img"></p><p>日志文件太大，手动删除或者设置最大日志大小限制</p><blockquote><h3 id="控制容器日志大小"><a href="#控制容器日志大小" class="headerlink" title="控制容器日志大小"></a><strong>控制容器日志大小</strong></h3><p>以上只是临时解决的方式，最好是创建容器时就控制日志的大小。</p><h4 id="运行时控制"><a href="#运行时控制" class="headerlink" title="运行时控制"></a><strong>运行时控制</strong></h4><p>启动容器时，我们可以通过参数来控制日志的文件个数和单个文件的大小</p><pre class="line-numbers language-none"><code class="language-none"># max-size 最大数值# max-file 最大日志数$ docker run -it --log-opt max-size&#x3D;10m --log-opt max-file&#x3D;3 redis<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>一两个容器还好，但是如果有很多容器需要管理，这样就很不方便了，最好还是可以统一管理。</p><h3 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a><strong>全局配置</strong></h3><p>创建或修改文件 <code>/etc/docker/daemon.json</code>，并增加以下配置</p><pre class="line-numbers language-none"><code class="language-none">&#123;    &quot;log-driver&quot;:&quot;json-file&quot;,    &quot;log-opts&quot;:&#123;        &quot;max-size&quot; :&quot;50m&quot;,&quot;max-file&quot;:&quot;3&quot;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>max-size&#x3D;50m，意味着一个容器日志大小上限是50M，  max-file&#x3D;3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。可以存在的最大日志文件数。如果超过最大值，则会删除最旧的文件。**仅在max-size设置时有效。默认为5。</p><p>随后重启 Docker 服务</p><p>不过已存在的容器不会生效，需要重建才可以</p></blockquote><p>转至 <a href="https://www.cnblogs.com/zhangmingcheng/p/13960496.html">https://www.cnblogs.com/zhangmingcheng/p/13960496.html</a></p><p>另一方面，docker所在的磁盘空间不足，linux一直往主磁盘写空间不足的日志，导致主磁盘的空间也不足</p><p><img src="https://img.lazysun.me/202302272359471.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>云服务器如何挂载磁盘</title>
      <link href="/p/523.html"/>
      <url>/p/523.html</url>
      
        <content type="html"><![CDATA[<p>我这边有台云服务器，属于华为云，由于当时购买服务器的时候，忘了买数据盘，所以数据都放在了系统盘，但是随着服务的增多，以及每个服务产生的数据的增多，系统盘已经快撑爆了。所以最近购买了数据盘，但是问题来了，数据盘买了，如何使用呢？如何分区？如何挂载目录？本文瑞哥将用亲身实战经历带大家见识一下，如果在看的小伙伴最近有这块的业务和需求可以好好看下，有任何问题可以在文章末尾的讨论区与我讨论，让我们直接开始。</p><h2 id="查询数据盘"><a href="#查询数据盘" class="headerlink" title="查询数据盘"></a>查询数据盘</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">fdisk</span> <span class="token parameter variable">-l</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输出：</p><pre class="line-numbers language-none"><code class="language-none">Disk &#x2F;dev&#x2F;sda: 80 GiB, 85899345920 bytes, 167772160 sectorsDisk model: VBS fileIOUnits: sectors of 1 * 512 &#x3D; 512 bytesSector size (logical&#x2F;physical): 512 bytes &#x2F; 512 bytesI&#x2F;O size (minimum&#x2F;optimal): 512 bytes &#x2F; 512 bytesDisklabel type: dosDisk identifier: 0xe29a7a02Device     Boot Start       End   Sectors Size Id Type&#x2F;dev&#x2F;sda1  *     2048 167772126 167770079  80G 83 LinuxDisk &#x2F;dev&#x2F;sdb: 100 GiB, 107374182400 bytes, 209715200 sectorsDisk model: VBS fileIOUnits: sectors of 1 * 512 &#x3D; 512 bytesSector size (logical&#x2F;physical): 512 bytes &#x2F; 512 bytesI&#x2F;O size (minimum&#x2F;optimal): 512 bytes &#x2F; 512 bytes <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由输出可知，这台全裸的云服务器有两个数据盘，分别为：</p><ul><li>&#x2F;dev&#x2F;sda：80 GiB</li><li>&#x2F;dev&#x2F;sdb：100 GiB</li></ul><p>&#x2F;dev&#x2F;sda为系统盘，&#x2F;dev&#x2F;sdb为数据盘，这里我们肯定是要对数据盘进行分区的，系统盘千万不要乱用，否则就会很难受，就像我们之前的服务器：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@wljslmz:~<span class="token comment"># df -lh</span>Filesystem      Size  Used Avail Use% Mounted onudev             16G     <span class="token number">0</span>   16G   <span class="token number">0</span>% /devtmpfs           <span class="token number">3</span>.1G   34M  <span class="token number">3</span>.1G   <span class="token number">2</span>% /run/dev/sda1        79G   71G  <span class="token number">4</span>.5G  <span class="token number">95</span>% /tmpfs            16G     <span class="token number">0</span>   16G   <span class="token number">0</span>% /dev/shmtmpfs           <span class="token number">5</span>.0M  <span class="token number">4</span>.0K  <span class="token number">5</span>.0M   <span class="token number">1</span>% /run/locktmpfs            16G     <span class="token number">0</span>   16G   <span class="token number">0</span>% /sys/fs/cgrouptmpfs           <span class="token number">3</span>.1G     <span class="token number">0</span>  <span class="token number">3</span>.1G   <span class="token number">0</span>% /run/user/0/dev/sdb1        98G   18G   76G  <span class="token number">19</span>% /dataoverlay          79G   71G  <span class="token number">4</span>.5G  <span class="token number">95</span>% /var/lib/docker/overlay2/2edf748d6f23e9939e0566bc197a1bcd6c6d877b409fecdfc87a6e7596526fe9/merged <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到之前的服务器系统盘直接干到了95%，不出意外的撑不过这周末。所以把原服务器系统盘数据迁移迫在眉睫！！！</p><p>那有朋友问了，为啥不对原服务器的系统盘进行扩容？</p><p>其实也是可以的，但是系统盘扩容贵不说，主要我新申请的服务器本身就是做容灾处理，正好借此机会迁移一下，原服务器后面就只放nginx和前端、以及部分Python相关的服务了。</p><p>言归正传，我们还是回到如何挂载和初始化磁盘的话题上。</p><h3 id="数据盘分区"><a href="#数据盘分区" class="headerlink" title="数据盘分区"></a>数据盘分区</h3><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">fdisk</span> /dev/sdb <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对<code>/dev/sdb</code>磁盘进行分区：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/53ebdd307aaf4c90acdc7b84b0f98fe6~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>由图可知，已经进入分区界面。</p><h3 id="输入n"><a href="#输入n" class="headerlink" title="输入n"></a>输入n</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0e9b12073bbe412da4e60cdf578b9af3~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>此时会出现两个选择：</p><ul><li>p：主分区</li><li>e：扩展分区</li></ul><p>这个时候我们选择主分区。</p><h3 id="输入p"><a href="#输入p" class="headerlink" title="输入p"></a>输入p</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/19f2230a212e481ea1ed07ea0cf73920~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>此时出现的是想设置几个分区，范围是1-4，我们默认选择就一个分区吧，简单点，直接回车就好，然后下面的每一步都直接回车，直接创建好后提示：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3dd7e1430ac24542a9fdacbb0e9f2e5a~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>这个时候就看了我们创建了一个新的分区，大小为100G。</p><h3 id="输入p-1"><a href="#输入p-1" class="headerlink" title="输入p"></a>输入p</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ff8824ebc46347e7966866d6d6a6835a~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>我们看到了新建的分区的详细信息。</p><h3 id="输入w"><a href="#输入w" class="headerlink" title="输入w"></a>输入w</h3><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0a04b639a5a6445d89a1c2144e3d2dc7~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>我们看到已经将分区结果写入分区表中了。</p><p>最后再执行命令：<code>partprobe</code>将新的分区表变更同步至操作系统。</p><p>到此分区就搞定了，下面进入格式化磁盘步骤。</p><h2 id="格式化磁盘"><a href="#格式化磁盘" class="headerlink" title="格式化磁盘"></a>格式化磁盘</h2><p>只需执行命令：</p><pre class="line-numbers language-none"><code class="language-none">mkfs -t ext4 &#x2F;dev&#x2F;sdb <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a5878f95e9748c797e8240a7f2463aa~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>直接输入“y”：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/54002a3931864c6b82a977acfca293a8~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>直接格式化磁盘也完成了，下面就进入挂载磁盘步骤了。</p><h2 id="挂载磁盘"><a href="#挂载磁盘" class="headerlink" title="挂载磁盘"></a>挂载磁盘</h2><p>在挂载前，我先看下数据盘到底有没有被挂载，执行以下命令：</p><pre class="line-numbers language-none"><code class="language-none">df -h <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b187763e82eb4985abff501df8582b14~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>可以看到只有系统盘&#x2F;dev&#x2F;sda1被挂载到了&#x2F;路径，并没有看到&#x2F;dev&#x2F;sdb数据盘的影子。</p><p>所以接下来，就开始挂载数据盘吧。</p><h3 id="新建挂载目录"><a href="#新建挂载目录" class="headerlink" title="新建挂载目录"></a>新建挂载目录</h3><p>执行命令：</p><pre class="line-numbers language-none"><code class="language-none">mkdir &#x2F;data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>新建&#x2F;data目录，用来挂载数据盘。</p><h3 id="挂载目录"><a href="#挂载目录" class="headerlink" title="挂载目录"></a>挂载目录</h3><p>执行命令：</p><pre class="line-numbers language-none"><code class="language-none">mount &#x2F;dev&#x2F;sdb &#x2F;data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/43a1f92d016c4128862176b3ca62d5ff~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>再执行命令：</p><pre class="line-numbers language-none"><code class="language-none">df -TH <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d236e4daffe2447fa347b95278d64031~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>可以清晰的看到，我们的数据盘已经成功挂载到了&#x2F;data目录。</p><p>至此挂载也完成了，但是，千万别忘了做最后一件事，那就是将分区挂载写入fstab文件，防止主机重启后分区丢失的问题！</p><h2 id="持久化fstab文件"><a href="#持久化fstab文件" class="headerlink" title="持久化fstab文件"></a>持久化fstab文件</h2><p>执行命令：</p><pre class="line-numbers language-none"><code class="language-none">blkid &#x2F;dev&#x2F;sdb <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f004a3f4d3014335b2e854b05c261519~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>可以查看到&#x2F;dev&#x2F;sdb的唯一编号，我们需要将这个唯一编号写入到fstab文件。</p><p>执行命令：</p><pre class="line-numbers language-none"><code class="language-none">vim &#x2F;etc&#x2F;fstab <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入以下条目：</p><pre class="line-numbers language-none"><code class="language-none">UUID&#x3D;f3f1c505-66a6-4e0c-bfde-7625e3abc551 &#x2F;data                ext4    defaults        0 2 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f50e56a5930747b994aa2157cf6d2ff9~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.image"></p><p>保存即可。</p><p>至此所有工作大功告成！</p><p>本文转自 <a href="https://juejin.cn/post/7201334455058530364">https://juejin.cn/post/7201334455058530364</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      <categories>
          
          <category> 转载 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器监控系统</title>
      <link href="/p/f651.html"/>
      <url>/p/f651.html</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus-Server"><a href="#Prometheus-Server" class="headerlink" title="Prometheus Server"></a>Prometheus Server</h2><p>Prometheus服务的主服务器，收集监控信息</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">9090</span>:9090 <span class="token parameter variable">--name</span> prometheus <span class="token parameter variable">--net</span><span class="token operator">=</span>host prom/prometheus<span class="token comment">#先基于prom/prometheus镜像随便运行一个容器，我们需要将其主配置文件复制一份进行更改</span><span class="token function">docker</span> <span class="token function">cp</span> prometheus:/etc/prometheus/prometheus.yml ./<span class="token comment">#复制prometheus容器中的主配置文件到宿主机本地</span><span class="token function">docker</span> <span class="token function">rm</span> <span class="token parameter variable">-f</span> prometheus <span class="token function">vim</span> prometheus.yml <span class="token comment">#找到如下行并修改</span>    - targets: <span class="token punctuation">[</span><span class="token string">'localhost:9090'</span>,<span class="token string">'localhost:8080'</span>,<span class="token string">'localhost:9100'</span>,<span class="token string">'192.168.171.150:9100'</span>,<span class="token string">'192.168.171.150:8080'</span>,<span class="token string">'192.168.171.152:9100'</span>,<span class="token string">'192.168.171.152:8080'</span><span class="token punctuation">]</span><span class="token comment">#上述内容看似杂乱无章，其实无非就是指定了本机的9090、8080、9100这三个端口，</span><span class="token comment">#还增加了另外两台被监控的服务器的8080端口和9100端口</span><span class="token comment">#若需要监控更多的服务器，只需依次在上面指定添加即可，当然了，被监控端需要运行前面的两个容器</span><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">9090</span>:9090 <span class="token parameter variable">-v</span> ./prometheus.yml:/etc/prometheus/prometheus.yml <span class="token parameter variable">--name</span> prometheus <span class="token parameter variable">--net</span><span class="token operator">=</span>host prom/prometheus<span class="token comment">#执行上述命令，运行新的prometheus容器，并将刚刚修改的主配置文件挂载到容器中的指定位置</span><span class="token comment">#以后若要修改主配置文件，则直接修改本地的即可。</span><span class="token comment">#挂载主配置文件后，本地的和容器内的相当于同一份，在本地修改内容的话，会同步到容器中</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Node-Exporter"><a href="#Node-Exporter" class="headerlink" title="Node Exporter"></a>Node Exporter</h2><p>收集Host硬件和操作系统的信息</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">9100</span>:9100 <span class="token parameter variable">-v</span> /proc:/host/proc <span class="token parameter variable">-v</span> /sys:/host/sys <span class="token parameter variable">-v</span> /:/rootfs <span class="token parameter variable">--net</span><span class="token operator">=</span>host <span class="token parameter variable">--restart</span><span class="token operator">=</span>always prom/node-exporter <span class="token parameter variable">--path.procfs</span> /host/proc <span class="token parameter variable">--path.sysfs</span> /host/sys --collector.filesystem.ignored-mount-points <span class="token string">"^/(sys|proc|dev|host|etc)($|/)"</span><span class="token comment">#基于“prom/node-exporter”镜像运行容器，可以去github官网搜索该镜像，以便了解其主要功能</span><span class="token comment">#注：每台需要被监控的主机都需要执行上述命令以便运行容器，以便收集主机信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="cAdvrisor"><a href="#cAdvrisor" class="headerlink" title="cAdvrisor"></a>cAdvrisor</h2><p>负责收集Host上运行的容器信息</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-v</span> /:/rootfs:ro <span class="token parameter variable">-v</span> /var/run:/var/run:rw <span class="token parameter variable">-v</span> /sys:/sys:ro <span class="token parameter variable">-v</span> /var/lib/docker:/var/lib/docker:ro <span class="token parameter variable">-p</span> <span class="token number">8080</span>:8080 <span class="token parameter variable">--detach</span><span class="token operator">=</span>true <span class="token parameter variable">--name</span><span class="token operator">=</span>cadvisor <span class="token parameter variable">--net</span><span class="token operator">=</span>host google/cadvisor<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="grafana"><a href="#grafana" class="headerlink" title="grafana"></a>grafana</h2><p>用来展示Prometheus监控操作界面（给我们提供一个友好的web界面）</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"> <span class="token function">mkdir</span> grafana-storage<span class="token function">chmod</span> <span class="token number">777</span> <span class="token parameter variable">-R</span> grafana-storage/<span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">3000</span>:3000 <span class="token parameter variable">--name</span> grafana <span class="token parameter variable">-v</span> ./grafana-storage:/var/lib/grafana <span class="token parameter variable">-e</span> <span class="token string">"GF_SECURITY_ADMIN_PASSWORD=123456"</span> grafana/grafana<span class="token comment">#上述命令中的“-e”选项是为了设置默认的登录用户admin，密码为“123456”。</span><span class="token comment">#如果启动容器的过程中，提示iptables等相关的错误信息，</span><span class="token comment">#则需要执行命令systemctl restart docker，重启docker服务，然后重新运行容器</span><span class="token comment">#但是需要注意，若运行容器时没有增加“--restart=always”选项的话，</span><span class="token comment">#那么在重启docker服务后，还需将所有容器手动重启。</span><span class="token comment">#重启所有容器命令“docker ps -a -q | xargs docker start”</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>grafana通过nginx进行转发</p><p>nginx和grafana均使用docker部署</p><p>grafana官方文档：<a href="https://grafana.com/tutorials/run-grafana-behind-a-proxy/">在反向代理|后面运行 Grafana格拉法纳实验室</a></p><p><strong>nginx配置</strong></p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token comment"># this is required to proxy Grafana Live WebSocket connections.</span><span class="token directive"><span class="token keyword">map</span> <span class="token variable">$http_upgrade</span> <span class="token variable">$connection_upgrade</span></span> <span class="token punctuation">&#123;</span>  <span class="token directive"><span class="token keyword">default</span> upgrade</span><span class="token punctuation">;</span>  '' <span class="token directive"><span class="token keyword">close</span></span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">upstream</span> grafana</span> <span class="token punctuation">&#123;</span>  <span class="token directive"><span class="token keyword">server</span> domain.com:3000</span><span class="token punctuation">;</span> <span class="token comment">#域名:端口 由于使用docker，所以不能像官方文档一样使用localhost</span><span class="token punctuation">&#125;</span><span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">&#123;</span>  <span class="token directive"><span class="token keyword">listen</span> <span class="token number">80</span></span><span class="token punctuation">;</span>  <span class="token directive"><span class="token keyword">root</span> /usr/share/nginx/html</span><span class="token punctuation">;</span>  <span class="token directive"><span class="token keyword">index</span> index.html index.htm</span><span class="token punctuation">;</span>  <span class="token directive"><span class="token keyword">location</span> /grafana/</span> <span class="token punctuation">&#123;</span>    <span class="token directive"><span class="token keyword">rewrite</span>  ^/grafana/(.*)  /<span class="token variable">$1</span> break</span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_set_header</span> Host <span class="token variable">$http_host</span></span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_pass</span> http://grafana</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span>  <span class="token comment"># Proxy Grafana Live WebSocket connections.</span>  <span class="token directive"><span class="token keyword">location</span> /grafana/api/live/</span> <span class="token punctuation">&#123;</span>    <span class="token directive"><span class="token keyword">rewrite</span>  ^/grafana/(.*)  /<span class="token variable">$1</span> break</span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_http_version</span> 1.1</span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_set_header</span> Upgrade <span class="token variable">$http_upgrade</span></span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_set_header</span> Connection <span class="token variable">$connection_upgrade</span></span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_set_header</span> Host <span class="token variable">$http_host</span></span><span class="token punctuation">;</span>    <span class="token directive"><span class="token keyword">proxy_pass</span> http://grafana</span><span class="token punctuation">;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>grafana配置</strong></p><pre class="line-numbers language-conf" data-language="conf"><code class="language-conf">[server]domain &#x3D; domain.comroot_url &#x3D; %(protocol)s:&#x2F;&#x2F;%(domain)s&#x2F;grafana&#x2F;serve_from_sub_path &#x3D; true<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>之后重启容器访问 <a href="http://domain.com/grafana">http://domain.com/grafana</a> 即可</p><h2 id="loki-promtail"><a href="#loki-promtail" class="headerlink" title="loki + promtail"></a>loki + promtail</h2><p>日志收集系统，在grafana中展示</p><p>docker-compose.yml文件：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">version</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token key atrule">services</span><span class="token punctuation">:</span>  <span class="token key atrule">promtail</span><span class="token punctuation">:</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> grafana/promtail<span class="token punctuation">:</span>2.2.0    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> promtail    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> ./promtail/promtail<span class="token punctuation">-</span>docker<span class="token punctuation">-</span>config.yaml<span class="token punctuation">:</span>/etc/promtail/docker<span class="token punctuation">-</span>config.yaml      <span class="token punctuation">-</span> /var/test/usr/<span class="token punctuation">:</span>/var/log/user/      <span class="token comment">#这里可依次将需要的日志文件夹挂载上去,因为有些服务日志是定期清楚更换的，所以不便挂载日志文件本身</span>    <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token string">"--config.file=/etc/promtail/docker-config.yaml"</span>  <span class="token key atrule">loki</span><span class="token punctuation">:</span>    <span class="token key atrule">image</span><span class="token punctuation">:</span> grafana/loki<span class="token punctuation">:</span>2.2.0    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> loki    <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>config.file=/etc/loki/local<span class="token punctuation">-</span>config.yaml    <span class="token key atrule">ports</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token string">"3100:3100"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>loki可能会出现日志过大现象，严重占用内存空间，所以使用docker run</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker</span> run <span class="token parameter variable">-it</span> --log-opt max-size<span class="token operator">=</span>10m --log-opt max-file<span class="token operator">=</span><span class="token number">3</span> <span class="token parameter variable">--name</span> loki  <span class="token parameter variable">-p</span> <span class="token number">3100</span>:3100 grafana/loki:2.2.0 <span class="token parameter variable">-config.file</span><span class="token operator">=</span>/etc/loki/local-config.yaml<span class="token comment"># max-size 最大数值</span><span class="token comment"># max-file 最大日志数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>promtail-docker-config.yaml 文件：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">server</span><span class="token punctuation">:</span>  <span class="token key atrule">http_listen_port</span><span class="token punctuation">:</span> <span class="token number">9080</span>  <span class="token key atrule">grpc_listen_port</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token key atrule">positions</span><span class="token punctuation">:</span>  <span class="token key atrule">filename</span><span class="token punctuation">:</span> /tmp/positions.yaml<span class="token key atrule">clients</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">url</span><span class="token punctuation">:</span> http<span class="token punctuation">:</span>//loki<span class="token punctuation">:</span>3100/loki/api/v1/push <span class="token comment">#loki主机的ip地址或域名</span><span class="token key atrule">scrape_configs</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> system    <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> localhost      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">job</span><span class="token punctuation">:</span> test        <span class="token key atrule">app</span><span class="token punctuation">:</span> user<span class="token punctuation">-</span>service        <span class="token key atrule">__path__</span><span class="token punctuation">:</span> /var/log/user/logs.txt    <span class="token key atrule">pipeline_stages</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">match</span><span class="token punctuation">:</span>          <span class="token key atrule">selector</span><span class="token punctuation">:</span> <span class="token string">'&#123;job="test"&#125;'</span>          <span class="token key atrule">stages</span><span class="token punctuation">:</span>           <span class="token punctuation">-</span> <span class="token key atrule">multiline</span><span class="token punctuation">:</span>              <span class="token key atrule">firstline</span><span class="token punctuation">:</span> <span class="token string">'\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;\s\d&#123;1,2&#125;:\d&#123;2&#125;:\d&#123;2&#125;.\d&#123;3&#125;\s*(INFO|ERROR|DEBUG|WARN|CRITICAL)'</span>              <span class="token comment">#使用正则匹配日志首行,比如java的error日志会打印出错误堆栈信息,会被promtail分解为多条日志</span>          <span class="token punctuation">-</span> <span class="token key atrule">regex</span><span class="token punctuation">:</span>              <span class="token key atrule">expression</span><span class="token punctuation">:</span> <span class="token string">'\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;\s\d&#123;1,2&#125;:\d&#123;2&#125;:\d&#123;2&#125;.\d&#123;3&#125;\s*(?P&lt;level>INFO|ERROR|DEBUG|WARN|CRITICAL)'</span>              <span class="token comment">#此处使用正则提取出日志等级,INFO|ERROR|DEBUG|WARN|CRITICAL,方便展示</span>          <span class="token punctuation">-</span> <span class="token key atrule">labels</span><span class="token punctuation">:</span>              <span class="token key atrule">level</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果grafana获取不到loki的数据：</p><ul><li>确定端口已开放</li><li>防火墙问题(遇到过，应该可以通过某些设置放开，但是我当时直接关了)</li></ul>]]></content>
      
      
      <categories>
          
          <category> tasks </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deploy </tag>
            
            <tag> prometheus </tag>
            
            <tag> 日志 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
